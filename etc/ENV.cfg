# Use structure similar to INI file.
# Values will be evaluated using ast.literal_eval() to determine data type,
#    so enclose string in single or double quotes and
#    make sure values are compatiple with ast.literal_eval().
# Use comment only on new line, inline comment is not supported

[DEFAULT]

HOST      :"bv23033.us-central1.gcp"
USER      :"shree"
WAREHOUSE :"COMPUTE_WH"
DATABASE  :"BHATBHATENI"
PASSWORD  :"@Mount123#"


EXTRACT_TGT : "EXT_TGT_SCHEMA"

EXT_SRC_SCHEMA : "bhat_bhateni"
SRC_DB      :"DW_DEV_STG"
TEMP_DB     :"DW_DEV_TMP"
TARGET_DB   :"DW_DEV_DWH"
ARCHIVE_DB  :"DW_DEV_STG_ARC"
VIEW_DB     :"DW_DEV_DWH_V"
ARCHIVE_DWH :"DW_DEV_ARC"
FILE_STAGE  :"FILE_STG"
VIEW_PREFIX :"V_"

SCRIPT_LU_TABLE      :"DWH_C_BATCH_SCRIPTS"
DWHNTLY_BATCH_LOG    :"DWH_C_BATCH_LOG"
DWH_PARAM_TABLE      :"DWH_C_PARAM"
AUDIT_TABLE          :"DWH_C_LOAD_AUDIT_LOG"
REJECT_PROCESS_TABLE :"DWH_C_REJ_TBL_PROCESS"

ROBLING_HOME        :r"C:\Users\shrikrishna.rai\PycharmProjects\ETL_basics"
ETLHOME             :${ROBLING_HOME}"/Code/dev"
SCRIPTS_DIR         :${ETLHOME}"/bin"
LIB_DIR             :${ETLHOME}"/lib"
SQL_DIR             :${ETLHOME}"/sql"
ETC_DIR             :${ETLHOME}"/etc"
CONTROL_SCRIPTS_DIR :${ETLHOME}"/control_scripts"

DATA_DIR            :${ROBLING_HOME}"/data"
BAD_DIR             :${DATA_DIR}"/bad"
EXTRACTS_DIR        :${DATA_DIR}"/extracts"
BOOKMARK_DIR        :${DATA_DIR}"/bookmark"
REJECT_DIR          :${DATA_DIR}"/reject"
ERROR_DIR           :${DATA_DIR}"/error"
SF_FILE_UPLOAD_DIR  :${DATA_DIR}
FILE_EXTRACT_DIR    :${DATA_DIR}"/extracts"

ARCHIVE_DIR         :${ROBLING_HOME}"/data_archive"
TMP_DIR             :${ROBLING_HOME}"/tmp"

LOG_DIR             :${ROBLING_HOME}"/log"
LOG_ARCHIVE_DIR     :${LOG_DIR}"/log_archive"

PRIMARY_CNCY_CDE    :"USD"

# DELAY_BOOKMARK = 0 if bookmark is to be updated every time it is set,
#                  1 if bookmark is to be updated at the end of script, on success or failure
DELAY_BOOKMARK : 1

# AUDIT_PROCESS = 0 : do not log audit,
#                 1 : insert audit normally,
#                 2 : collect audit in a list and insert into table only at the end of script, on success or failure
AUDIT_PROCESS : 2

ECOMM_STORE   :"'0000'"

SNOWFLAKE_PUT_OPTIONS : "AUTO_COMPRESS = TRUE"
AUTO_COMPRESS         : "AUTO_COMPRESS=FALSE"
FORCE                 : "FORCE=FALSE"
FILE_FORMAT           : "gz"
PURGE                 : "PURGE=TRUE"

# Archive log process archives log files older than LOG_ARCHIVE_DAYS
LOG_ARCHIVE_DAYS      : 5

DEFAULT_MIN_KEY       :-1
